{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.7\n",
      "1.5.0\n",
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "print(hyperopt.__version__)\n",
    "\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n",
    "\n",
    "import lightgbm\n",
    "print(lightgbm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt를 이용한 하이퍼파라미터 튜닝\n",
    "\n",
    "1. 검색 공간 설정\n",
    "2. 대체 모델을 위한 목적 함수 지정\n",
    "3. 최적의 파라미터를 유추"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 검색 공간\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x와 -15 ~ 15까지 1간격으로 입력 변수 y 설정\n",
    "search_space = {'x': hp.quniform('x',-10,10,1), \n",
    "                'y': hp.quniform('y',-15,15,1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 목적 함수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성. 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    return retval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 최적 입력값을 유추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 416.67trial/s, best loss: -224.0]\n",
      "best: {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# Step 3: 최적 입력값 유추\n",
    "# 입력 결괏값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# Step 4: TPE 알고리즘을 사용하여 최적화를 수행\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(\n",
    "    fn=objective_func,               # 목적 함수\n",
    "    space=search_space,              # 검색 공간\n",
    "    algo=tpe.suggest,                # 탐색 알고리즘 (TPE)\n",
    "    max_evals=5,                     # 최대 시도 횟수\n",
    "    trials=trial_val,                # Trials 객체\n",
    "    rstate=np.random.default_rng(seed=0)  # 랜덤 시드\n",
    ")\n",
    "\n",
    "print('best:', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 514.88trial/s, best loss: -296.0]\n",
      "best: {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest,\n",
    "               max_evals=20, trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "\n",
    "print('best:', best_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': 56.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': 61.0, 'status': 'ok'},\n",
       " {'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': 56.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': 61.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -40.0, 'status': 'ok'},\n",
       " {'loss': 281.0, 'status': 'ok'},\n",
       " {'loss': 64.0, 'status': 'ok'},\n",
       " {'loss': 100.0, 'status': 'ok'},\n",
       " {'loss': 60.0, 'status': 'ok'},\n",
       " {'loss': -39.0, 'status': 'ok'},\n",
       " {'loss': 1.0, 'status': 'ok'},\n",
       " {'loss': -164.0, 'status': 'ok'},\n",
       " {'loss': 21.0, 'status': 'ok'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmin( )에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값} 와 같은 딕셔너리임. \n",
    "trial_val.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, -6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 10,\n",
       " 'spec': None,\n",
       " 'result': {'loss': -296.0, 'status': 'ok'},\n",
       " 'misc': {'tid': 10,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'x': [10], 'y': [10]},\n",
       "  'vals': {'x': [2.0], 'y': [15.0]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2025, 1, 3, 11, 31, 55, 192000),\n",
       " 'refresh_time': datetime.datetime(2025, 1, 3, 11, 31, 55, 192000)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_val.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5   -6.0   5.0   -64.0\n",
       "6   -4.0  10.0  -184.0\n",
       "7    4.0  -2.0    56.0\n",
       "8   -4.0  12.0  -224.0\n",
       "9    9.0   1.0    61.0\n",
       "10   2.0  15.0  -296.0\n",
       "11  10.0   7.0   -40.0\n",
       "12  -9.0 -10.0   281.0\n",
       "13  -8.0   0.0    64.0\n",
       "14  -0.0  -5.0   100.0\n",
       "15  -0.0  -3.0    60.0\n",
       "16   1.0   2.0   -39.0\n",
       "17   9.0   4.0     1.0\n",
       "18   6.0  10.0  -164.0\n",
       "19   9.0   3.0    21.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성\n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성\n",
    "result_df = pd.DataFrame({'x': trial_val.vals['x'], 'y': trial_val.vals['y'], 'losses': losses})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, tpe, Trials, hp\n",
    "from hyperopt import hp\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target']= dataset.target\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label, test_size=0.2, random_state=156 )\n",
    "\n",
    "# 앞에서 추출한 학습 데이터를 다시 학습과 검증 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1, random_state=156 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 검색 공간\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "# 하이퍼 파라미터 검색 공간\n",
    "search_space = {'n_estimators':scope.int(hp.quniform('n_estimators', 50,300,10)),\n",
    "                'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)), \n",
    "                'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
    "                'subsample': hp.uniform('subsample', 0.5,1.0),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "                }\n",
    "\n",
    "\n",
    "# 교재\n",
    "# from hyperopt import hp\n",
    "\n",
    "# # max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# # colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2 사이 정규 분포된 값으로 검색.\n",
    "# xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "#                     'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "#                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "#                     'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "#                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 목적 함수\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "def objective_func_xgb(params):\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=params['n_estimators'], \n",
    "        max_depth=params['max_depth'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=42,\n",
    "        eval_metric='logloss', \n",
    "    )\n",
    "    score_mean = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    # accuracy는 cv=3 개수만큼 roc-auc 결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "    return {'loss': -1*score_mean , 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# 교재\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from xgboost import XGBClassifier\n",
    "# from hyperopt import STATUS_OK\n",
    "\n",
    "# # fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임.\n",
    "# # XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함.\n",
    "# # 정확도는 높을수록 더 좋은 수치임. -1 * 정확도를 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "# def objective_func(search_space):\n",
    "#     # 수행 시간 절약을 위해 nestimators는 100으로 축소\n",
    "#     xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "#                             min_child_weight=int(search_space['min_child_weight']),\n",
    "#                             learning_rate=search_space['learning_rate'],\n",
    "#                             colsample_bytree=search_space['colsample_bytree'],\n",
    "#                             eval_metric='logloss')\n",
    "#     accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "    \n",
    "#     # accuracy는 cv=3 개수만큼 roc-auc 결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "#     return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:07<00:00,  1.34s/trial, best loss: -0.9714285714285715]\n",
      "best: {'colsample_bytree': 0.7640743223872615, 'learning_rate': 0.16871176836822976, 'max_depth': 5.0, 'n_estimators': 120.0, 'subsample': 0.5041991491400559}\n"
     ]
    }
   ],
   "source": [
    "# 3. 최적 입력값을 유추\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hyperopt Trials 초기화\n",
    "trial_val = Trials()\n",
    "# Hyperparameter Tuning 실행\n",
    "best_params = fmin(fn=objective_func_xgb,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trial_val,\n",
    "            #rstate=np.random.default_rng(seed=9)\n",
    "            )\n",
    "\n",
    "print('best:', best_params)\n",
    "\n",
    "# 교재\n",
    "# from hyperopt import fmin, tpe, Trials\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# trial_val = Trials()\n",
    "# best = fmin(fn=objective_func,\n",
    "#             space=xgb_search_space,\n",
    "#             algo=tpe.suggest,\n",
    "#             max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "#             trials=trial_val, \n",
    "#             rstate=np.random.default_rng(seed=9))\n",
    "# print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5424149213362504,\n",
       " 'learning_rate': 0.12601372924444681,\n",
       " 'max_depth': 17.0,\n",
       " 'min_child_weight': 2.0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적의 파라미터를 적용한 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_probs=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred) \n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "\n",
    "    print('오차 행렬:\\n', confusion)\n",
    "    print(f'정확도: {accuracy}, 정밀도: {precision}, 재현율: {recall},\\\n",
    "    F1: {f1}, AUC:{roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost+HyperOpt accuracy 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(n_estimators= int(best_params['n_estimators']),\n",
    "                           max_depth= int(best_params['max_depth']),\n",
    "                           learning_rate= best_params['learning_rate'],\n",
    "                           subsample= best_params['subsample'],\n",
    "                           colsample_bytree= best_params['colsample_bytree'],\n",
    "                           random_state= 42,\n",
    "                           eval_metric= 'logloss'\n",
    "                           )\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "pred= best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print('XGBoost+HyperOpt accuracy', accuracy)\n",
    "\n",
    "#교재\n",
    "# xgb_wrapper = XGBClassifier(n_estimators=400,\n",
    "#                             learning_rate=round(best['learning_rate'], 5),\n",
    "#                             max_depth=int(best['max_depth']),\n",
    "#                             min_child_weight=int(best['min_child_weight']),\n",
    "#                             colsample_bytree=round(best['colsample_bytree'], 5)\n",
    "#                            )\n",
    "\n",
    "# evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "# xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss',\n",
    "#                 eval_set=evals, verbose=True)\n",
    "\n",
    "# preds = xgb_wrapper.predict(X_test)\n",
    "# pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# get_clf_eval(y_test, preds, pred_proba)\n",
    "# print('###XGBoost+HyperOpt###')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
