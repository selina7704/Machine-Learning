{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X,y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]): # sex ==1, survived=0으로 예측, 아니면 1로 예측측\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i]=0\n",
    "            else:\n",
    "                pred[i]=1\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행.\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selina\\AppData\\Local\\Temp\\ipykernel_27596\\340051843.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\selina\\AppData\\Local\\Temp\\ipykernel_27596\\340051843.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Cabin'].fillna('N', inplace=True)\n",
      "C:\\Users\\selina\\AppData\\Local\\Temp\\ipykernel_27596\\340051843.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna('N', inplace=True)\n",
      "C:\\Users\\selina\\AppData\\Local\\Temp\\ipykernel_27596\\340051843.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fare'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "# 전처리리\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "# 데이터 분할할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성 & 학습습\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "my_pred = myclf.predict(X_test)\n",
    "accuracy_score(y_test, my_pred) #정확도도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 18],\n",
       "       [20, 49]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, my_pred) #row: 실제값, col: 예측측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7313432835820896, 0.7101449275362319)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 정밀도/재현율율\n",
    "precision_score(y_test, my_pred), recall_score(y_test, my_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "digits.data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p.149 MyFakeClassifier 를 이용한 정확도 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       " 0       3    1  22.0      1      0   7.2500      7         3\n",
       " 1       1    0  38.0      1      0  71.2833      2         0\n",
       " 2       3    0  26.0      0      0   7.9250      7         3\n",
       " 3       1    0  35.0      1      0  53.1000      2         3\n",
       " 4       3    1  35.0      0      0   8.0500      7         3,\n",
       " 0    0\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    0\n",
       " Name: Survived, dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#titanic_df\n",
    "X_titanic_df.head(), y_titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리리\n",
    "#X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.156\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred) \n",
    "    recall = recall_score(y_test, pred)\n",
    "\n",
    "    print(confusion)\n",
    "    print('*'*20)\n",
    "    print(accuracy, precision, recall)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  14]\n",
      " [ 13  48]]\n",
      "********************\n",
      "0.8491620111731844 0.7741935483870968 0.7868852459016393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\selina\\.conda\\envs\\ml_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱회귀 분류모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.predict(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "# 정확도, 정밀도, 재현율\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46235897, 0.53764103, 1.        ],\n",
       "       [0.87877764, 0.12122236, 0.        ],\n",
       "       [0.87720996, 0.12279004, 0.        ],\n",
       "       [0.88243424, 0.11756576, 0.        ],\n",
       "       [0.85531356, 0.14468644, 0.        ],\n",
       "       [0.8821124 , 0.1178876 , 0.        ],\n",
       "       [0.88850554, 0.11149446, 0.        ],\n",
       "       [0.20887546, 0.79112454, 1.        ],\n",
       "       [0.7828625 , 0.2171375 , 0.        ],\n",
       "       [0.36900515, 0.63099485, 1.        ],\n",
       "       [0.8996726 , 0.1003274 , 0.        ],\n",
       "       [0.87516493, 0.12483507, 0.        ],\n",
       "       [0.87720405, 0.12279595, 0.        ],\n",
       "       [0.88846023, 0.11153977, 0.        ],\n",
       "       [0.43679356, 0.56320644, 1.        ],\n",
       "       [0.85911091, 0.14088909, 0.        ],\n",
       "       [0.90378902, 0.09621098, 0.        ],\n",
       "       [0.73334014, 0.26665986, 0.        ],\n",
       "       [0.72465745, 0.27534255, 0.        ],\n",
       "       [0.17155259, 0.82844741, 1.        ],\n",
       "       [0.75350245, 0.24649755, 0.        ],\n",
       "       [0.61874254, 0.38125746, 0.        ],\n",
       "       [0.85475655, 0.14524345, 0.        ],\n",
       "       [0.81469453, 0.18530547, 0.        ],\n",
       "       [0.88809435, 0.11190565, 0.        ],\n",
       "       [0.76539046, 0.23460954, 0.        ],\n",
       "       [0.85952951, 0.14047049, 0.        ],\n",
       "       [0.92578728, 0.07421272, 0.        ],\n",
       "       [0.71952205, 0.28047795, 0.        ],\n",
       "       [0.69541965, 0.30458035, 0.        ],\n",
       "       [0.05283233, 0.94716767, 1.        ],\n",
       "       [0.18289504, 0.81710496, 1.        ],\n",
       "       [0.87311192, 0.12688808, 0.        ],\n",
       "       [0.17384623, 0.82615377, 1.        ],\n",
       "       [0.60038577, 0.39961423, 0.        ],\n",
       "       [0.76539046, 0.23460954, 0.        ],\n",
       "       [0.92761165, 0.07238835, 0.        ],\n",
       "       [0.38942094, 0.61057906, 1.        ],\n",
       "       [0.94712439, 0.05287561, 0.        ],\n",
       "       [0.89615617, 0.10384383, 0.        ],\n",
       "       [0.64882189, 0.35117811, 0.        ],\n",
       "       [0.9165774 , 0.0834226 , 0.        ],\n",
       "       [0.17839976, 0.82160024, 1.        ],\n",
       "       [0.29220824, 0.70779176, 1.        ],\n",
       "       [0.36975957, 0.63024043, 1.        ],\n",
       "       [0.36974348, 0.63025652, 1.        ],\n",
       "       [0.08115048, 0.91884952, 1.        ],\n",
       "       [0.64037739, 0.35962261, 0.        ],\n",
       "       [0.05114997, 0.94885003, 1.        ],\n",
       "       [0.88806026, 0.11193974, 0.        ],\n",
       "       [0.40762082, 0.59237918, 1.        ],\n",
       "       [0.88846023, 0.11153977, 0.        ],\n",
       "       [0.86732504, 0.13267496, 0.        ],\n",
       "       [0.27473422, 0.72526578, 1.        ],\n",
       "       [0.69061685, 0.30938315, 0.        ],\n",
       "       [0.8027326 , 0.1972674 , 0.        ],\n",
       "       [0.77343604, 0.22656396, 0.        ],\n",
       "       [0.87720893, 0.12279107, 0.        ],\n",
       "       [0.84594817, 0.15405183, 0.        ],\n",
       "       [0.56719059, 0.43280941, 0.        ],\n",
       "       [0.71981035, 0.28018965, 0.        ],\n",
       "       [0.8993561 , 0.1006439 , 0.        ],\n",
       "       [0.4546948 , 0.5453052 , 1.        ],\n",
       "       [0.48515761, 0.51484239, 1.        ],\n",
       "       [0.55554327, 0.44445673, 0.        ],\n",
       "       [0.90546086, 0.09453914, 0.        ],\n",
       "       [0.3335828 , 0.6664172 , 1.        ],\n",
       "       [0.40622397, 0.59377603, 1.        ],\n",
       "       [0.04818894, 0.95181106, 1.        ],\n",
       "       [0.85176603, 0.14823397, 0.        ],\n",
       "       [0.87128045, 0.12871955, 0.        ],\n",
       "       [0.83172979, 0.16827021, 0.        ],\n",
       "       [0.89615395, 0.10384605, 0.        ],\n",
       "       [0.05205613, 0.94794387, 1.        ],\n",
       "       [0.80125009, 0.19874991, 0.        ],\n",
       "       [0.88846023, 0.11153977, 0.        ],\n",
       "       [0.6521454 , 0.3478546 , 0.        ],\n",
       "       [0.81622988, 0.18377012, 0.        ],\n",
       "       [0.16443388, 0.83556612, 1.        ],\n",
       "       [0.87720893, 0.12279107, 0.        ],\n",
       "       [0.2053203 , 0.7946797 , 1.        ],\n",
       "       [0.35416781, 0.64583219, 1.        ],\n",
       "       [0.06883007, 0.93116993, 1.        ],\n",
       "       [0.86680223, 0.13319777, 0.        ],\n",
       "       [0.05112474, 0.94887526, 1.        ],\n",
       "       [0.0497509 , 0.9502491 , 1.        ],\n",
       "       [0.84642395, 0.15357605, 0.        ],\n",
       "       [0.87456636, 0.12543364, 0.        ],\n",
       "       [0.1254033 , 0.8745967 , 1.        ],\n",
       "       [0.88846023, 0.11153977, 0.        ],\n",
       "       [0.88846023, 0.11153977, 0.        ],\n",
       "       [0.76539046, 0.23460954, 0.        ],\n",
       "       [0.76747528, 0.23252472, 0.        ],\n",
       "       [0.88846023, 0.11153977, 0.        ],\n",
       "       [0.36974348, 0.63025652, 1.        ],\n",
       "       [0.92431569, 0.07568431, 0.        ],\n",
       "       [0.07118014, 0.92881986, 1.        ],\n",
       "       [0.89935186, 0.10064814, 0.        ],\n",
       "       [0.49483086, 0.50516914, 1.        ],\n",
       "       [0.03493848, 0.96506152, 1.        ],\n",
       "       [0.49840577, 0.50159423, 1.        ],\n",
       "       [0.90564477, 0.09435523, 0.        ],\n",
       "       [0.05220917, 0.94779083, 1.        ],\n",
       "       [0.90252027, 0.09747973, 0.        ],\n",
       "       [0.47019326, 0.52980674, 1.        ],\n",
       "       [0.87172675, 0.12827325, 0.        ],\n",
       "       [0.85906449, 0.14093551, 0.        ],\n",
       "       [0.85176633, 0.14823367, 0.        ],\n",
       "       [0.5508535 , 0.4491465 , 0.        ],\n",
       "       [0.89203997, 0.10796003, 0.        ],\n",
       "       [0.88282383, 0.11717617, 0.        ],\n",
       "       [0.89119024, 0.10880976, 0.        ],\n",
       "       [0.59687576, 0.40312424, 0.        ],\n",
       "       [0.34589867, 0.65410133, 1.        ],\n",
       "       [0.88809435, 0.11190565, 0.        ],\n",
       "       [0.92907337, 0.07092663, 0.        ],\n",
       "       [0.87549843, 0.12450157, 0.        ],\n",
       "       [0.80147756, 0.19852244, 0.        ],\n",
       "       [0.07397976, 0.92602024, 1.        ],\n",
       "       [0.93135952, 0.06864048, 0.        ],\n",
       "       [0.88846897, 0.11153103, 0.        ],\n",
       "       [0.8692094 , 0.1307906 , 0.        ],\n",
       "       [0.93630431, 0.06369569, 0.        ],\n",
       "       [0.67783316, 0.32216684, 0.        ],\n",
       "       [0.98839801, 0.01160199, 0.        ],\n",
       "       [0.88846897, 0.11153103, 0.        ],\n",
       "       [0.88382579, 0.11617421, 0.        ],\n",
       "       [0.68332408, 0.31667592, 0.        ],\n",
       "       [0.32247482, 0.67752518, 1.        ],\n",
       "       [0.67812202, 0.32187798, 0.        ],\n",
       "       [0.03493848, 0.96506152, 1.        ],\n",
       "       [0.54607166, 0.45392834, 0.        ],\n",
       "       [0.26482926, 0.73517074, 1.        ],\n",
       "       [0.55621798, 0.44378202, 0.        ],\n",
       "       [0.43058259, 0.56941741, 1.        ],\n",
       "       [0.6483601 , 0.3516399 , 0.        ],\n",
       "       [0.25140715, 0.74859285, 1.        ],\n",
       "       [0.81372189, 0.18627811, 0.        ],\n",
       "       [0.89612913, 0.10387087, 0.        ],\n",
       "       [0.1964315 , 0.8035685 , 1.        ],\n",
       "       [0.09100419, 0.90899581, 1.        ],\n",
       "       [0.85176633, 0.14823367, 0.        ],\n",
       "       [0.8819987 , 0.1180013 , 0.        ],\n",
       "       [0.89880375, 0.10119625, 0.        ],\n",
       "       [0.90842206, 0.09157794, 0.        ],\n",
       "       [0.33163798, 0.66836202, 1.        ],\n",
       "       [0.92436016, 0.07563984, 0.        ],\n",
       "       [0.76576859, 0.23423141, 0.        ],\n",
       "       [0.08200847, 0.91799153, 1.        ],\n",
       "       [0.83177097, 0.16822903, 0.        ],\n",
       "       [0.57082474, 0.42917526, 0.        ],\n",
       "       [0.36858274, 0.63141726, 1.        ],\n",
       "       [0.3638666 , 0.6361334 , 1.        ],\n",
       "       [0.87726382, 0.12273618, 0.        ],\n",
       "       [0.22236729, 0.77763271, 1.        ],\n",
       "       [0.1193585 , 0.8806415 , 1.        ],\n",
       "       [0.51288657, 0.48711343, 0.        ],\n",
       "       [0.86716381, 0.13283619, 0.        ],\n",
       "       [0.24832333, 0.75167667, 1.        ],\n",
       "       [0.30980527, 0.69019473, 1.        ],\n",
       "       [0.85036956, 0.14963044, 0.        ],\n",
       "       [0.20678898, 0.79321102, 1.        ],\n",
       "       [0.90877789, 0.09122211, 0.        ],\n",
       "       [0.33364951, 0.66635049, 1.        ],\n",
       "       [0.62006642, 0.37993358, 0.        ],\n",
       "       [0.34907773, 0.65092227, 1.        ],\n",
       "       [0.11564485, 0.88435515, 1.        ],\n",
       "       [0.69041931, 0.30958069, 0.        ],\n",
       "       [0.90840304, 0.09159696, 0.        ],\n",
       "       [0.10703268, 0.89296732, 1.        ],\n",
       "       [0.88850554, 0.11149446, 0.        ],\n",
       "       [0.14594324, 0.85405676, 1.        ],\n",
       "       [0.74903497, 0.25096503, 0.        ],\n",
       "       [0.75980803, 0.24019197, 0.        ],\n",
       "       [0.59829167, 0.40170833, 0.        ],\n",
       "       [0.93770626, 0.06229374, 0.        ],\n",
       "       [0.85905757, 0.14094243, 0.        ],\n",
       "       [0.45525469, 0.54474531, 1.        ],\n",
       "       [0.37320762, 0.62679238, 1.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)],axis=1)\n",
    "pred_proba_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이진화 Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_threshold = 0.4 # 이 기준보다 큰 수치를 생존 아니면 사망\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1) # 새로운 예측값값 #0.53764103, 0.12122236...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정밀도와 재현율의 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 20]\n",
      " [10 51]]\n",
      "********************\n",
      "0.8324022346368715 0.7183098591549296 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_1) #새로운 예측값으로 이진화한 예측값값\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_clf_eval(y_test, pred)\n",
    "[[104  14]\n",
    " [ 13  48]]\n",
    "********************\n",
    "0.8491620111731844 0.7741935483870968 0.7868852459016393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1-score\n",
    "\n",
    "재현율과 정밀도의 조화 평균: 그 모델의 전체적인 성능을 볼 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804878048780488"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC (Receiver Operation Characteristics)\n",
    "\n",
    "민감도 어떻게 달라지는지 보는 지표 (=재현율, 실제 양성을 맞춘 비율)\n",
    "거짓긍정율 = 1-특이도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53764103, 0.12122236, 0.12279004, 0.11756576, 0.14468644,\n",
       "       0.1178876 , 0.11149446, 0.79112454, 0.2171375 , 0.63099485,\n",
       "       0.1003274 , 0.12483507, 0.12279595, 0.11153977, 0.56320644,\n",
       "       0.14088909, 0.09621098, 0.26665986, 0.27534255, 0.82844741,\n",
       "       0.24649755, 0.38125746, 0.14524345, 0.18530547, 0.11190565,\n",
       "       0.23460954, 0.14047049, 0.07421272, 0.28047795, 0.30458035,\n",
       "       0.94716767, 0.81710496, 0.12688808, 0.82615377, 0.39961423,\n",
       "       0.23460954, 0.07238835, 0.61057906, 0.05287561, 0.10384383,\n",
       "       0.35117811, 0.0834226 , 0.82160024, 0.70779176, 0.63024043,\n",
       "       0.63025652, 0.91884952, 0.35962261, 0.94885003, 0.11193974,\n",
       "       0.59237918, 0.11153977, 0.13267496, 0.72526578, 0.30938315,\n",
       "       0.1972674 , 0.22656396, 0.12279107, 0.15405183, 0.43280941,\n",
       "       0.28018965, 0.1006439 , 0.5453052 , 0.51484239, 0.44445673,\n",
       "       0.09453914, 0.6664172 , 0.59377603, 0.95181106, 0.14823397,\n",
       "       0.12871955, 0.16827021, 0.10384605, 0.94794387, 0.19874991,\n",
       "       0.11153977, 0.3478546 , 0.18377012, 0.83556612, 0.12279107,\n",
       "       0.7946797 , 0.64583219, 0.93116993, 0.13319777, 0.94887526,\n",
       "       0.9502491 , 0.15357605, 0.12543364, 0.8745967 , 0.11153977,\n",
       "       0.11153977, 0.23460954, 0.23252472, 0.11153977, 0.63025652,\n",
       "       0.07568431, 0.92881986, 0.10064814, 0.50516914, 0.96506152,\n",
       "       0.50159423, 0.09435523, 0.94779083, 0.09747973, 0.52980674,\n",
       "       0.12827325, 0.14093551, 0.14823367, 0.4491465 , 0.10796003,\n",
       "       0.11717617, 0.10880976, 0.40312424, 0.65410133, 0.11190565,\n",
       "       0.07092663, 0.12450157, 0.19852244, 0.92602024, 0.06864048,\n",
       "       0.11153103, 0.1307906 , 0.06369569, 0.32216684, 0.01160199,\n",
       "       0.11153103, 0.11617421, 0.31667592, 0.67752518, 0.32187798,\n",
       "       0.96506152, 0.45392834, 0.73517074, 0.44378202, 0.56941741,\n",
       "       0.3516399 , 0.74859285, 0.18627811, 0.10387087, 0.8035685 ,\n",
       "       0.90899581, 0.14823367, 0.1180013 , 0.10119625, 0.09157794,\n",
       "       0.66836202, 0.07563984, 0.23423141, 0.91799153, 0.16822903,\n",
       "       0.42917526, 0.63141726, 0.6361334 , 0.12273618, 0.77763271,\n",
       "       0.8806415 , 0.48711343, 0.13283619, 0.75167667, 0.69019473,\n",
       "       0.14963044, 0.79321102, 0.09122211, 0.66635049, 0.37993358,\n",
       "       0.65092227, 0.88435515, 0.30958069, 0.09159696, 0.89296732,\n",
       "       0.11149446, 0.85405676, 0.25096503, 0.24019197, 0.40170833,\n",
       "       0.06229374, 0.14094243, 0.54474531, 0.62679238])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "pred_proba_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fprs, tprs, threshold = roc_curve(y_test, pred_proba_class1)\n",
    "\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fprs, tprs, label = 'ROC')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9025423728813561)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, pred_proba_class1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 1의 ROC-AUC = 0.92 - 모델의 편별 성능이 우수하다 <br>\n",
    "모델 2의 ROC-AUC = 0.78 - 모델 1보다 성능이 낮다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
